`#000000`

# Objectives<br/>
## Objective 1:<br/>


# Key concepts<br/>
## Data Quality Metrics
### Accuracy
AKA Correctness, Validity<br/>
How well does our data reflect the real world? Are false items likely?<br/>
### Integrity
AKA Completeness<br/>
How well does our data cover the real world? Are missing items likely?<br/>
### Consistency
AKA Uniformity<br/>
How well does our data conform to a single standard? Are discrepancies likely?<br/>
### Timeliness
AKA Recency, Availability<br/>
How up-to-date is our data? Are stale items likely?<br/>

### Reliability
Is the data consistently accurate over time?<br/>
Can the data be depended upon for making critical decisions? 


## Data and Metadata Standards
# Open Standards
Open standards are guidelines for technology that anyone can use and contribute to<br/>
<br/>
Benefits:<br/>
Compatibility: They help different systems and tools talk to each other smoothly<br/>
Flexibility: You're not locked into using products from just one company<br/>
Innovation: Encourages new ideas and improvements by allowing more people to contribute<br/>
Cost-effective: Often free to use, which can save money on technology costs<br/>

# Fair data standard
Findable, Accessible, Interoperable, Reusable<br/>

# Dublin Core ^TM Metadata Initiative (DCMI)



## Navigating quality issues in XML Data Formats
# Key Facts about XML
Human and Machine Readable <br/>
Tagging<br/>
Hierarchical Structure <br/>

# Strengths
Human-readable<br/>
Flexibility<br/>
Interoperability<br/>
# Weaknesses
Verbose syntax<br/>
Parsing overhead<br/>
Lack of schema enforcement<br/>

## Navigating quality issues in CSV Data Formats
# Strengths
Human-readable<br/>
Simple structure<br/>

# Weaknesses
Lack of standardisation<br/>
Limited data types<br/>
Fragility<br/>

## Navigating quality issues in JSON Data Formats
# What is JSON
JavaScript Object Notation (JSON), is a lightweight data interchange format that offers simplicity and efficiency. It facilitates human readability and machine parsing while providing flexibility in data structuring through key-value pairs and arrays.<br/>
JSON has become the preferred data format for web applications and Application Programming Interfaces (APIs) due to its simplicity, flexibility, and compatibility with JavaScript. It is widely used for transmitting data between a server and a web application, making it an integral part of modern web development. <br/>
# What is an API?
An API is a set of protocols, routines, and tools that specify how software components should interact and communicate with each other. <br/>
<br/>
In simpler terms, an API acts as a messenger that allows different software applications to talk to each other and share data or functionality.<br/>
<br/>
For example, when you use a mobile app to book a  taxi service, the app communicates with the taxi company's server through an API to request and receive information about available drivers, pricing, and estimated arrival times. <br/>

# Strengths
Human-readable: <br/>
Lightweight: <br/>
Native JavaScript support: <br/>

# Weaknesses
Optionality of schema:<br/>
Limited data types: <br/>
Nesting complexity: <br/>

# What is a Key Value Pair?
In SQL terms, it's a unique key to link to a value

# Converting XML to JSON
freeformatter.com and ConvertJSON.com<br/>


## Strategies for ensuring data quality
# Data Validation Tools

## Data Testing Methodologies
**Data Quality Management Platforms** like Informatica Data Quality, Talend Data Quality, and IBM InfoSphere Information Analyser offer comprehensive data quality management solutions. <br/><br/>
**Data Profiilng Software Tools** like SAS Data Quality and Oracle Data Profiling enable organisations to analyse the structure, content, and quality characteristics of their data. <br/><br/>
**Data Validation Frameworks** like Apache Griffin and Great Expectations provide open-source solutions for validating and monitoring data quality. 

# Data Lineage
**Definition:** Data lineage refers to the lifecycle of data, encompassing its origin, usage, and movement over time<br/><br/>
**Importance:** It ensures transparency, aids in understanding data usage patterns, traces errors, and enhances trust in data for strategic decision-making<br/><br/>

# UIDs vs UUIDs
UIDs are unique within their own context, while Universally Unique Identifiers (UUIDs) are standardised and globally unique across different systems<br/>

## Data Testing Methodologies
# Horizontal Testing
Testing data consistency and integrity across multiple data sources
# Historical Analysis
Analysing Data Quality over time to identify trends, patterns and anomalies
# Rule Based Testing
Validating data against predefined rules or criteria.
# Statistical Testing
Identifying anomalies and outliers within datasets using statistical techniques

<br/><br/><br/>
## Data quality testing tools and frameworks
# Open-Source libraries and tools
e.g. Pandas-Profiling, Apache Griffin
# Commercial data quality tools
e.g. Informatica, Talend
# Manual Testing
Sampling, Spot-Checking, Data Validation through comparison with trusted sources<br/>


# Questions<br/>
## Question 1:<br/>

# Self Research<br/>

# Reflections<br/>

`Testing Backticks (ctrl+e)`
