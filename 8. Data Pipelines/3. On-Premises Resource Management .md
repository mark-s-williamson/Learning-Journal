# Setting Up and Maintaining On-Premise Data Infrastructure

## Key Components of On-Premise Data Infrastructure

- **Compute Servers**
- **Storage Arrays:** File Servers, NAS (Network-Attached Storage), or SAN (Storage Area Network)
- **Network Components:** Switches, firewalls, load balancers
- **Operating Systems and Virtualisation Layers:** Commonly Linux, sometimes virtualised through VMware, Proxmox, or KVM

---

## Setting Up Infrastructure for Data Workloads

### 1. Hardware and Capacity Planning
- Estimate volume, concurrency, and processing needs.  
- Choose between:
  - **High-performance servers** (more CPU, RAM)
  - **Storage-heavy servers** (RAID arrays, SSDs)
- Consider redundancy: RAID, backup drives.

### 2. Network Topology
- Flat LAN or segmented networks for security?  
- Ensure low-latency links between compute and storage nodes.

### 3. Environment Configuration
- Install and configure the OS (commonly Linux).  
- Set up Python, Docker, Java, or other runtime environments.  
- Create a standardised directory and permission structure for data handling.

### 4. Security Hardening
- Apply firewalls and restrict SSH access.  
- Disable unused network ports and services.  
- Use local authentication or integrate with enterprise systems such as **LDAP** or **Active Directory**.  
- Configure audit logging and alerts.

---

## Maintaining On-Premise Infrastructure

### 1. Patch and Update Management
- Apply OS and software patches regularly.  
- Automate updates using tools like **yum-cron**, **unattended-upgrades**, or **Ansible**.

### 2. Monitoring and Logging
- Use **Prometheus**, **Zabbix**, or **Nagios** to track CPU, memory, and disk usage.  
- Set up alert thresholds for outages or resource spikes.

### 3. Backup and Disaster Recovery
- Establish a backup schedule and retention policy.  
- Test restoration procedures regularly.  
- Use snapshotting, replication, or external drives/cloud sync.

### 4. Documentation and Knowledge Transfer
- Maintain clear setup and support documentation.  
- Use internal wikis or shared repositories for continuity during staff changes.

---

## Trade-Offs of On-Premise Infrastructure
- **Data Sovereignty:** Keep data within national borders.  
- **Low Latency:** Suitable for real-time or high-performance workloads.  
- **Cost Predictability:** Fixed hardware costs over time.  
- **Regulatory Compliance:** Easier control over data handling and access.

---

# Managing Computational Resources for Data Pipelines

## CPU
**CPU-bound operations include:**
- Complex joins  
- Mathematical operations on large datasets  
- Data parsing and decoding (e.g. JSON, XML)  
- Serial operations on large collections  

## RAM
**RAM-intensive operations include:**
- Sorting large datasets  
- In-memory joins and groupings  
- Buffering streams or large file reads  
- Holding intermediate results across stages  

## Disk I/O
**Common I/O bottlenecks:**
- Writing large intermediate files between pipeline stages  
- Frequent access to NAS  
- Reading/writing highly compressed or fragmented files  

## Network Bandwidth
Monitor for congestion, latency, and throughput issues between nodes.

---

### Observability and Resource Profiling Tools
- `htop` / `top`  
- `nmon` / `glances`  
- `docker stats`  
- **Grafana** + **Prometheus**

---

# Techniques for Efficient Resource Utilisation

| Area | Techniques |
|------|-------------|
| **CPU** | Push filters early, use vectorised operations, profile pipelines, apply parallelism with control |
| **Memory Efficiency** | Avoid peak hours, use cron/orchestrators, apply throttling and rate limiting, prioritise jobs |
| **I/O** | Write only what’s needed, choose efficient file formats, batch file access, use asynchronous I/O |
| **Memory Limits** | Use chunk processing, streaming APIs, drop unused objects, use memory-mapped files |

---

# Load Balancing and Resource Scheduling

## Core Strategies
Load balancing on-premises comes down to two key approaches:
1. **Scheduling jobs over time**
2. **Distributing tasks across available hardware**

### Why Scheduling Matters
- Improved efficiency  
- Higher data quality  
- Streamlined workflows  
- Reduced errors  
- Increased processing speed

### Strategies for Load Management
1. **Job Staggering**  
2. **Workload Prioritisation**  
3. **Throttling and Resource Limits**  
4. **Dependency-Aware Scheduling**  
5. **Off-Peak Scheduling**

### Tools for Scheduling
- `cron`  
- **Apache Airflow**  
- **Prefect**  
- **Kubernetes CronJobs**  
- **SLURM**

---

# Using Docker and Kubernetes for On-Premise Infrastructure Management

## What Changes When Using Docker On-Premises?

| Factor | Cloud | On-Premises |
|--------|--------|-------------|
| **Provisioning** | Auto-scaling VMs, managed services | Manual server setup, finite capacity |
| **Storage** | S3, EBS, or managed persistent volumes | Must set up NFS, RAID arrays, or local volumes manually |
| **Networking** | Load balancers, VPCs, DNS included | Configure switches, firewalls, and IPs manually |
| **Monitoring / Logging** | Cloud-native dashboards and metrics | Integrate Prometheus, ELK, or similar tools yourself |
| **High Availability (HA)** | Built-in across zones/regions | Must build HA clusters manually |
| **Security** | IAM roles, secrets managers, network policies | Must harden hosts, manage secrets, restrict access manually |

### Managing the Underlying Host
- Storage drivers and file permissions  
- Networking between containers  
- Image registry access  

---

## What Changes When Using Kubernetes On-Premises?

| Factor | Cloud | On-Premises |
|--------|--------|-------------|
| **Cluster Provisioning** | Managed services like EKS/GKE | Must set up control plane, worker nodes, networking (CNI), and service mesh manually |
| **Storage Provisioning** | Dynamic volume provisioning | No dynamic volumes by default — configure NFS, Ceph, or hostPath manually |
| **Node Scaling** | Auto-scaling | Requires physical hardware expansion |
| **Load Balancing** | Built-in | Configure your own (e.g., HAProxy, MetalLB) |
| **Secrets and Configs** | Managed by cloud secrets managers | Must use local secrets management or tools like Vault |

---

## Glossary of Terms
| Term | Meaning |
|------|----------|
| **EKS / GKE** | Elastic Kubernetes Service / Google Kubernetes Engine |
| **CNI** | Container Network Interface |
| **NFS** | Network File System |
| **VM** | Virtual Machine |
| **HAProxy** | High Availability Proxy |
| **MetalLB** | Metal Load Balancer |
| **AWS** | Amazon Web Services |
